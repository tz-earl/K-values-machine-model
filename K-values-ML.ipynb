{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##import tensorflow as tf\n",
    "##tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import keras as ks\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.729100e-03</td>\n",
       "      <td>1.509</td>\n",
       "      <td>0.52360</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.965300e-03</td>\n",
       "      <td>1.558</td>\n",
       "      <td>0.54105</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.224300e-03</td>\n",
       "      <td>1.607</td>\n",
       "      <td>0.55851</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.507300e-03</td>\n",
       "      <td>1.656</td>\n",
       "      <td>0.57596</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.815600e-03</td>\n",
       "      <td>1.705</td>\n",
       "      <td>0.59341</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.150700e-03</td>\n",
       "      <td>1.753</td>\n",
       "      <td>0.61087</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.513700e-03</td>\n",
       "      <td>1.802</td>\n",
       "      <td>0.62832</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.906100e-03</td>\n",
       "      <td>1.850</td>\n",
       "      <td>0.64577</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.329200e-03</td>\n",
       "      <td>1.898</td>\n",
       "      <td>0.66323</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.784300e-03</td>\n",
       "      <td>1.946</td>\n",
       "      <td>0.68068</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.272800e-03</td>\n",
       "      <td>1.994</td>\n",
       "      <td>0.69813</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.796100e-03</td>\n",
       "      <td>2.042</td>\n",
       "      <td>0.71558</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.355600e-03</td>\n",
       "      <td>2.090</td>\n",
       "      <td>0.73304</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.952500e-03</td>\n",
       "      <td>2.137</td>\n",
       "      <td>0.75049</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.588200e-03</td>\n",
       "      <td>2.184</td>\n",
       "      <td>0.76794</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.264100e-03</td>\n",
       "      <td>2.231</td>\n",
       "      <td>0.78540</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.981500e-03</td>\n",
       "      <td>2.278</td>\n",
       "      <td>0.80285</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.741700e-03</td>\n",
       "      <td>2.325</td>\n",
       "      <td>0.82030</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.054600e-02</td>\n",
       "      <td>2.372</td>\n",
       "      <td>0.83776</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.139600e-02</td>\n",
       "      <td>2.418</td>\n",
       "      <td>0.85521</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.229200e-02</td>\n",
       "      <td>2.464</td>\n",
       "      <td>0.87266</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.323700e-02</td>\n",
       "      <td>2.510</td>\n",
       "      <td>0.89012</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.423000e-02</td>\n",
       "      <td>2.556</td>\n",
       "      <td>0.90757</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.527400e-02</td>\n",
       "      <td>2.602</td>\n",
       "      <td>0.92502</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.636900e-02</td>\n",
       "      <td>2.647</td>\n",
       "      <td>0.94248</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.751700e-02</td>\n",
       "      <td>2.692</td>\n",
       "      <td>0.95993</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.871900e-02</td>\n",
       "      <td>2.737</td>\n",
       "      <td>0.97738</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.997500e-02</td>\n",
       "      <td>2.782</td>\n",
       "      <td>0.99484</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.128700e-02</td>\n",
       "      <td>2.827</td>\n",
       "      <td>1.01230</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.265600e-02</td>\n",
       "      <td>2.871</td>\n",
       "      <td>1.02970</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.06470</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>6.204900e-18</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.08210</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>1.611300e-17</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.09960</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>2.610900e-17</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.11700</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>3.619100e-17</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.13450</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>4.635500e-17</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.15190</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>5.659900e-17</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.16940</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>6.691800e-17</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.18680</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>7.731100e-17</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.20430</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>8.777400e-17</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.22170</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>9.830300e-17</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.23920</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>1.089000e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.25660</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>1.195500e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.27410</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>1.302600e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.29150</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>1.410200e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.30900</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>1.518400e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.32650</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>1.627000e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.34390</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>1.736000e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.36140</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>1.845500e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.37880</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>1.955300e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.39630</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>2.065500e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.41370</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>2.176000e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.43120</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>2.286700e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.44860</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>2.397700e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.46610</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>2.508900e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.48350</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>2.620200e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.50100</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>2.731700e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.51840</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2.843300e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.53590</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>2.955000e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.55330</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>3.066700e-16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.57080</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>549 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0      1        2  3  4       5\n",
       "0    1.729100e-03  1.509  0.52360  3  2  0.0100\n",
       "1    1.965300e-03  1.558  0.54105  3  2  0.0100\n",
       "2    2.224300e-03  1.607  0.55851  3  2  0.0100\n",
       "3    2.507300e-03  1.656  0.57596  3  2  0.0100\n",
       "4    2.815600e-03  1.705  0.59341  3  2  0.0100\n",
       "5    3.150700e-03  1.753  0.61087  3  2  0.0100\n",
       "6    3.513700e-03  1.802  0.62832  3  2  0.0100\n",
       "7    3.906100e-03  1.850  0.64577  3  2  0.0100\n",
       "8    4.329200e-03  1.898  0.66323  3  2  0.0100\n",
       "9    4.784300e-03  1.946  0.68068  3  2  0.0100\n",
       "10   5.272800e-03  1.994  0.69813  3  2  0.0100\n",
       "11   5.796100e-03  2.042  0.71558  3  2  0.0100\n",
       "12   6.355600e-03  2.090  0.73304  3  2  0.0100\n",
       "13   6.952500e-03  2.137  0.75049  3  2  0.0100\n",
       "14   7.588200e-03  2.184  0.76794  3  2  0.0100\n",
       "15   8.264100e-03  2.231  0.78540  3  2  0.0100\n",
       "16   8.981500e-03  2.278  0.80285  3  2  0.0100\n",
       "17   9.741700e-03  2.325  0.82030  3  2  0.0100\n",
       "18   1.054600e-02  2.372  0.83776  3  2  0.0100\n",
       "19   1.139600e-02  2.418  0.85521  3  2  0.0100\n",
       "20   1.229200e-02  2.464  0.87266  3  2  0.0100\n",
       "21   1.323700e-02  2.510  0.89012  3  2  0.0100\n",
       "22   1.423000e-02  2.556  0.90757  3  2  0.0100\n",
       "23   1.527400e-02  2.602  0.92502  3  2  0.0100\n",
       "24   1.636900e-02  2.647  0.94248  3  2  0.0100\n",
       "25   1.751700e-02  2.692  0.95993  3  2  0.0100\n",
       "26   1.871900e-02  2.737  0.97738  3  2  0.0100\n",
       "27   1.997500e-02  2.782  0.99484  3  2  0.0100\n",
       "28   2.128700e-02  2.827  1.01230  3  2  0.0100\n",
       "29   2.265600e-02  2.871  1.02970  3  2  0.0100\n",
       "..            ...    ...      ... .. ..     ...\n",
       "519  0.000000e+00  0.000  1.06470  9  4  0.0001\n",
       "520  6.204900e-18  0.001  1.08210  9  4  0.0001\n",
       "521  1.611300e-17  0.001  1.09960  9  4  0.0001\n",
       "522  2.610900e-17  0.001  1.11700  9  4  0.0001\n",
       "523  3.619100e-17  0.001  1.13450  9  4  0.0001\n",
       "524  4.635500e-17  0.001  1.15190  9  4  0.0001\n",
       "525  5.659900e-17  0.001  1.16940  9  4  0.0001\n",
       "526  6.691800e-17  0.001  1.18680  9  4  0.0001\n",
       "527  7.731100e-17  0.001  1.20430  9  4  0.0001\n",
       "528  8.777400e-17  0.001  1.22170  9  4  0.0001\n",
       "529  9.830300e-17  0.001  1.23920  9  4  0.0001\n",
       "530  1.089000e-16  0.001  1.25660  9  4  0.0001\n",
       "531  1.195500e-16  0.001  1.27410  9  4  0.0001\n",
       "532  1.302600e-16  0.001  1.29150  9  4  0.0001\n",
       "533  1.410200e-16  0.001  1.30900  9  4  0.0001\n",
       "534  1.518400e-16  0.001  1.32650  9  4  0.0001\n",
       "535  1.627000e-16  0.001  1.34390  9  4  0.0001\n",
       "536  1.736000e-16  0.001  1.36140  9  4  0.0001\n",
       "537  1.845500e-16  0.001  1.37880  9  4  0.0001\n",
       "538  1.955300e-16  0.001  1.39630  9  4  0.0001\n",
       "539  2.065500e-16  0.001  1.41370  9  4  0.0001\n",
       "540  2.176000e-16  0.001  1.43120  9  4  0.0001\n",
       "541  2.286700e-16  0.001  1.44860  9  4  0.0001\n",
       "542  2.397700e-16  0.001  1.46610  9  4  0.0001\n",
       "543  2.508900e-16  0.001  1.48350  9  4  0.0001\n",
       "544  2.620200e-16  0.001  1.50100  9  4  0.0001\n",
       "545  2.731700e-16  0.001  1.51840  9  4  0.0001\n",
       "546  2.843300e-16  0.001  1.53590  9  4  0.0001\n",
       "547  2.955000e-16  0.001  1.55330  9  4  0.0001\n",
       "548  3.066700e-16  0.001  1.57080  9  4  0.0001\n",
       "\n",
       "[549 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read in the entire data set just for eyeballing.\n",
    "pd_data = pd.read_csv('K_data.csv', header=None)\n",
    "np_data = np.array(pd_data.values, dtype=np.float32) ## float32 might be better if using a GPU\n",
    "pd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.6582e-04, 9.4500e-01, 1.5010e+00, ..., 4.0000e+00, 1.0000e-02,\n",
       "        2.0000e-01],\n",
       "       [6.9525e-03, 2.1370e+00, 7.5049e-01, ..., 2.0000e+00, 1.0000e-02,\n",
       "        5.0000e-01],\n",
       "       [5.4947e-12, 1.1000e-02, 5.2360e-01, ..., 4.0000e+00, 1.0000e-03,\n",
       "        6.0000e-01],\n",
       "       ...,\n",
       "       [1.3298e-10, 2.5000e-02, 1.2217e+00, ..., 4.0000e+00, 1.0000e-03,\n",
       "        9.9180e+02],\n",
       "       [2.5089e-16, 1.0000e-03, 1.4835e+00, ..., 4.0000e+00, 1.0000e-04,\n",
       "        9.9600e+02],\n",
       "       [1.9636e-06, 2.7700e-01, 9.0757e-01, ..., 2.0000e+00, 1.0000e-04,\n",
       "        9.9640e+02]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read in the training data, which includes both the input features and the outputs K.\n",
    "pd_train = pd.read_csv('K_training_randomized.csv', header=None)\n",
    "np_train = np.array(pd_train.values, dtype=np.float32) ## float32 might be better if using a GPU\n",
    "np_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5010e+00, 9.0000e+00, 4.0000e+00, 1.0000e-02],\n",
       "       [7.5049e-01, 3.0000e+00, 2.0000e+00, 1.0000e-02],\n",
       "       [5.2360e-01, 9.0000e+00, 4.0000e+00, 1.0000e-03],\n",
       "       ...,\n",
       "       [1.2217e+00, 9.0000e+00, 4.0000e+00, 1.0000e-03],\n",
       "       [1.4835e+00, 9.0000e+00, 4.0000e+00, 1.0000e-04],\n",
       "       [9.0757e-01, 3.0000e+00, 2.0000e+00, 1.0000e-04]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Extract the input features: theta, m, n, h_star\n",
    "features = np_train[:, 2:6]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.137, 0.011, 0.03 , 0.022], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Extract the correct outputs K\n",
    "correct_outputs = np_train[:, 1]\n",
    "correct_outputs[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the test data, which includes both the input features and the outputs K.\n",
    "pd_test = pd.read_csv('K_testing.csv', header=None)\n",
    "np_test = pd_test.values\n",
    "num_tests = len(np_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/earl/Desktop/jupyenv-p3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 2,851\n",
      "Trainable params: 2,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##  Define a model.\n",
    "layer_0 = ks.layers.Dense(units=50, input_shape=[4])\n",
    "layer_1 = ks.layers.Dense(units=50, input_shape=[4])\n",
    "layer_2 = ks.layers.Dense(units=1)\n",
    "model_0 = ks.Sequential([layer_0, layer_1, layer_2])\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.compile(loss='mean_squared_error',\n",
    "              optimizer=ks.optimizers.Adam(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/earl/Desktop/jupyenv-p3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/250\n",
      "540/540 [==============================] - 0s 419us/step - loss: 277.2665\n",
      "Epoch 2/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 22.8493\n",
      "Epoch 3/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 3.8196\n",
      "Epoch 4/250\n",
      "540/540 [==============================] - 0s 22us/step - loss: 1.5647\n",
      "Epoch 5/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 1.0697\n",
      "Epoch 6/250\n",
      "540/540 [==============================] - 0s 24us/step - loss: 0.9169\n",
      "Epoch 7/250\n",
      "540/540 [==============================] - 0s 23us/step - loss: 0.8502\n",
      "Epoch 8/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.8388\n",
      "Epoch 9/250\n",
      "540/540 [==============================] - 0s 22us/step - loss: 0.8308\n",
      "Epoch 10/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.8262\n",
      "Epoch 11/250\n",
      "540/540 [==============================] - 0s 27us/step - loss: 0.8341\n",
      "Epoch 12/250\n",
      "540/540 [==============================] - 0s 17us/step - loss: 0.8136\n",
      "Epoch 13/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.8035\n",
      "Epoch 14/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.8073\n",
      "Epoch 15/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.7826\n",
      "Epoch 16/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.7767\n",
      "Epoch 17/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.7624\n",
      "Epoch 18/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.7493\n",
      "Epoch 19/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.7492\n",
      "Epoch 20/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.7175\n",
      "Epoch 21/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.6954\n",
      "Epoch 22/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.6987\n",
      "Epoch 23/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.6417\n",
      "Epoch 24/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.5948\n",
      "Epoch 25/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.5628\n",
      "Epoch 26/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.5682\n",
      "Epoch 27/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.6696\n",
      "Epoch 28/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.6037\n",
      "Epoch 29/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.5693\n",
      "Epoch 30/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.4292\n",
      "Epoch 31/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.3519\n",
      "Epoch 32/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2952\n",
      "Epoch 33/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2533\n",
      "Epoch 34/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2921\n",
      "Epoch 35/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.3207\n",
      "Epoch 36/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2694\n",
      "Epoch 37/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2185\n",
      "Epoch 38/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.3825\n",
      "Epoch 39/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.3648\n",
      "Epoch 40/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.3058\n",
      "Epoch 41/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2109\n",
      "Epoch 42/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2229\n",
      "Epoch 43/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2080\n",
      "Epoch 44/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2536\n",
      "Epoch 45/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2185\n",
      "Epoch 46/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2559\n",
      "Epoch 47/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.3362\n",
      "Epoch 48/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2848\n",
      "Epoch 49/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.2479\n",
      "Epoch 50/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2187\n",
      "Epoch 51/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.3526\n",
      "Epoch 52/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2796\n",
      "Epoch 53/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2018\n",
      "Epoch 54/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2262\n",
      "Epoch 55/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2096\n",
      "Epoch 56/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2130\n",
      "Epoch 57/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2588\n",
      "Epoch 58/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2454\n",
      "Epoch 59/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2182\n",
      "Epoch 60/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.4297\n",
      "Epoch 61/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.3236\n",
      "Epoch 62/250\n",
      "540/540 [==============================] - 0s 23us/step - loss: 0.2739\n",
      "Epoch 63/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2135\n",
      "Epoch 64/250\n",
      "540/540 [==============================] - 0s 22us/step - loss: 0.2195\n",
      "Epoch 65/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.2680\n",
      "Epoch 66/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.2173\n",
      "Epoch 67/250\n",
      "540/540 [==============================] - 0s 24us/step - loss: 0.2531\n",
      "Epoch 68/250\n",
      "540/540 [==============================] - 0s 23us/step - loss: 0.2445\n",
      "Epoch 69/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2234\n",
      "Epoch 70/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2657\n",
      "Epoch 71/250\n",
      "540/540 [==============================] - 0s 22us/step - loss: 0.2764\n",
      "Epoch 72/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2311\n",
      "Epoch 73/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2753\n",
      "Epoch 74/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.3263\n",
      "Epoch 75/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.3162\n",
      "Epoch 76/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2198\n",
      "Epoch 77/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.2649\n",
      "Epoch 78/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2011\n",
      "Epoch 79/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2092\n",
      "Epoch 80/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2271\n",
      "Epoch 81/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.2433\n",
      "Epoch 82/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.1969\n",
      "Epoch 83/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2172\n",
      "Epoch 84/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2193\n",
      "Epoch 85/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.1984\n",
      "Epoch 86/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2020\n",
      "Epoch 87/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2234\n",
      "Epoch 88/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2528\n",
      "Epoch 89/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2462\n",
      "Epoch 90/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2608\n",
      "Epoch 91/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2661\n",
      "Epoch 92/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2667\n",
      "Epoch 93/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2219\n",
      "Epoch 94/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2396\n",
      "Epoch 95/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540/540 [==============================] - 0s 22us/step - loss: 0.2153\n",
      "Epoch 96/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2951\n",
      "Epoch 97/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.3524\n",
      "Epoch 98/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2438\n",
      "Epoch 99/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2409\n",
      "Epoch 100/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2098\n",
      "Epoch 101/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2398\n",
      "Epoch 102/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.4008\n",
      "Epoch 103/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2861\n",
      "Epoch 104/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.3288\n",
      "Epoch 105/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2794\n",
      "Epoch 106/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2096\n",
      "Epoch 107/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2110\n",
      "Epoch 108/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2060\n",
      "Epoch 109/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2204\n",
      "Epoch 110/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2515\n",
      "Epoch 111/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2479\n",
      "Epoch 112/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2147\n",
      "Epoch 113/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.1942\n",
      "Epoch 114/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2287\n",
      "Epoch 115/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2408\n",
      "Epoch 116/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2311\n",
      "Epoch 117/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.1850\n",
      "Epoch 118/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2215\n",
      "Epoch 119/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2257\n",
      "Epoch 120/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2195\n",
      "Epoch 121/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2135\n",
      "Epoch 122/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2235\n",
      "Epoch 123/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.2212\n",
      "Epoch 124/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2034\n",
      "Epoch 125/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.2528\n",
      "Epoch 126/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2469\n",
      "Epoch 127/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2100\n",
      "Epoch 128/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.1995\n",
      "Epoch 129/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2162\n",
      "Epoch 130/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2042\n",
      "Epoch 131/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2185\n",
      "Epoch 132/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2335\n",
      "Epoch 133/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2331\n",
      "Epoch 134/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2382\n",
      "Epoch 135/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2383\n",
      "Epoch 136/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2089\n",
      "Epoch 137/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2120\n",
      "Epoch 138/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2272\n",
      "Epoch 139/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2694\n",
      "Epoch 140/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.1988\n",
      "Epoch 141/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2123\n",
      "Epoch 142/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2275\n",
      "Epoch 143/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.3293\n",
      "Epoch 144/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2523\n",
      "Epoch 145/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2045\n",
      "Epoch 146/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2357\n",
      "Epoch 147/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2264\n",
      "Epoch 148/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2056\n",
      "Epoch 149/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.1983\n",
      "Epoch 150/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2291\n",
      "Epoch 151/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2160\n",
      "Epoch 152/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2138\n",
      "Epoch 153/250\n",
      "540/540 [==============================] - 0s 22us/step - loss: 0.2296\n",
      "Epoch 154/250\n",
      "540/540 [==============================] - 0s 23us/step - loss: 0.2315\n",
      "Epoch 155/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2095\n",
      "Epoch 156/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2052\n",
      "Epoch 157/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2145\n",
      "Epoch 158/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2494\n",
      "Epoch 159/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2917\n",
      "Epoch 160/250\n",
      "540/540 [==============================] - 0s 24us/step - loss: 0.2068\n",
      "Epoch 161/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.1910\n",
      "Epoch 162/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2136\n",
      "Epoch 163/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.1920\n",
      "Epoch 164/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2368\n",
      "Epoch 165/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2308\n",
      "Epoch 166/250\n",
      "540/540 [==============================] - 0s 17us/step - loss: 0.2079\n",
      "Epoch 167/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2034\n",
      "Epoch 168/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.1921\n",
      "Epoch 169/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2388\n",
      "Epoch 170/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2891\n",
      "Epoch 171/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2631\n",
      "Epoch 172/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2208\n",
      "Epoch 173/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2336\n",
      "Epoch 174/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2371\n",
      "Epoch 175/250\n",
      "540/540 [==============================] - 0s 22us/step - loss: 0.2446\n",
      "Epoch 176/250\n",
      "540/540 [==============================] - 0s 22us/step - loss: 0.2213\n",
      "Epoch 177/250\n",
      "540/540 [==============================] - 0s 22us/step - loss: 0.2433\n",
      "Epoch 178/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2771\n",
      "Epoch 179/250\n",
      "540/540 [==============================] - 0s 23us/step - loss: 0.2734\n",
      "Epoch 180/250\n",
      "540/540 [==============================] - 0s 23us/step - loss: 0.2791\n",
      "Epoch 181/250\n",
      "540/540 [==============================] - 0s 22us/step - loss: 0.2545\n",
      "Epoch 182/250\n",
      "540/540 [==============================] - 0s 23us/step - loss: 0.2152\n",
      "Epoch 183/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2632\n",
      "Epoch 184/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.2412\n",
      "Epoch 185/250\n",
      "540/540 [==============================] - 0s 22us/step - loss: 0.2432\n",
      "Epoch 186/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2292\n",
      "Epoch 187/250\n",
      "540/540 [==============================] - 0s 22us/step - loss: 0.2695\n",
      "Epoch 188/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.2261\n",
      "Epoch 189/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2586\n",
      "Epoch 190/250\n",
      "540/540 [==============================] - 0s 22us/step - loss: 0.2084\n",
      "Epoch 191/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540/540 [==============================] - 0s 23us/step - loss: 0.2443\n",
      "Epoch 192/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.2695\n",
      "Epoch 193/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2569\n",
      "Epoch 194/250\n",
      "540/540 [==============================] - 0s 22us/step - loss: 0.2392\n",
      "Epoch 195/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.2579\n",
      "Epoch 196/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2556\n",
      "Epoch 197/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.3077\n",
      "Epoch 198/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2173\n",
      "Epoch 199/250\n",
      "540/540 [==============================] - 0s 22us/step - loss: 0.2490\n",
      "Epoch 200/250\n",
      "540/540 [==============================] - 0s 22us/step - loss: 0.2175\n",
      "Epoch 201/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.2986\n",
      "Epoch 202/250\n",
      "540/540 [==============================] - 0s 20us/step - loss: 0.1988\n",
      "Epoch 203/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.2008\n",
      "Epoch 204/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.2431\n",
      "Epoch 205/250\n",
      "540/540 [==============================] - 0s 25us/step - loss: 0.2503\n",
      "Epoch 206/250\n",
      "540/540 [==============================] - 0s 29us/step - loss: 0.2522\n",
      "Epoch 207/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.2414\n",
      "Epoch 208/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.2566\n",
      "Epoch 209/250\n",
      "540/540 [==============================] - 0s 22us/step - loss: 0.2394\n",
      "Epoch 210/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.2659\n",
      "Epoch 211/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2398\n",
      "Epoch 212/250\n",
      "540/540 [==============================] - 0s 22us/step - loss: 0.2466\n",
      "Epoch 213/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2298\n",
      "Epoch 214/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.2053\n",
      "Epoch 215/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2374\n",
      "Epoch 216/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2751\n",
      "Epoch 217/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.1986\n",
      "Epoch 218/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2403\n",
      "Epoch 219/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2089\n",
      "Epoch 220/250\n",
      "540/540 [==============================] - 0s 17us/step - loss: 0.2259\n",
      "Epoch 221/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2159\n",
      "Epoch 222/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2352\n",
      "Epoch 223/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2161\n",
      "Epoch 224/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2160\n",
      "Epoch 225/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2039\n",
      "Epoch 226/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2224\n",
      "Epoch 227/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2271\n",
      "Epoch 228/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2264\n",
      "Epoch 229/250\n",
      "540/540 [==============================] - 0s 17us/step - loss: 0.2179\n",
      "Epoch 230/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2376\n",
      "Epoch 231/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2656\n",
      "Epoch 232/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.1964\n",
      "Epoch 233/250\n",
      "540/540 [==============================] - 0s 17us/step - loss: 0.2028\n",
      "Epoch 234/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2183\n",
      "Epoch 235/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2477\n",
      "Epoch 236/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2266\n",
      "Epoch 237/250\n",
      "540/540 [==============================] - 0s 17us/step - loss: 0.2206\n",
      "Epoch 238/250\n",
      "540/540 [==============================] - 0s 17us/step - loss: 0.2642\n",
      "Epoch 239/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2314\n",
      "Epoch 240/250\n",
      "540/540 [==============================] - 0s 17us/step - loss: 0.2136\n",
      "Epoch 241/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.3346\n",
      "Epoch 242/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.3256\n",
      "Epoch 243/250\n",
      "540/540 [==============================] - 0s 18us/step - loss: 0.2094\n",
      "Epoch 244/250\n",
      "540/540 [==============================] - 0s 26us/step - loss: 0.2242\n",
      "Epoch 245/250\n",
      "540/540 [==============================] - 0s 25us/step - loss: 0.2685\n",
      "Epoch 246/250\n",
      "540/540 [==============================] - 0s 24us/step - loss: 0.2475\n",
      "Epoch 247/250\n",
      "540/540 [==============================] - 0s 21us/step - loss: 0.2630\n",
      "Epoch 248/250\n",
      "540/540 [==============================] - 0s 26us/step - loss: 0.2144\n",
      "Epoch 249/250\n",
      "540/540 [==============================] - 0s 19us/step - loss: 0.2281\n",
      "Epoch 250/250\n",
      "540/540 [==============================] - 0s 22us/step - loss: 0.2238\n",
      "Finished training the model\n"
     ]
    }
   ],
   "source": [
    "history_0 = model_0.fit(features, correct_outputs, epochs=250, verbose=True)\n",
    "print(\"Finished training the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f168c47b7b8>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel(\"Loss Magnitude\")\n",
    "plt.plot(history_0.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 2.256197452545166, Expected: 1.5090000000000001\n",
      "Prediction: 1.7513728141784668, Expected: 1.915\n",
      "Prediction: 1.3969426155090332, Expected: 0.9540000000000001\n",
      "Prediction: 0.4709588289260864, Expected: 0.547\n",
      "Prediction: -0.020979464054107666, Expected: 0.214\n",
      "Prediction: -0.37540972232818604, Expected: 0.031\n",
      "Prediction: 0.3027198314666748, Expected: 0.179\n",
      "Prediction: -0.18925464153289795, Expected: 0.022000000000000002\n",
      "Prediction: -0.6079341173171997, Expected: 0.001\n",
      "\n",
      "Mean error on test set: 0.3350118001302083\n",
      "Mean error % on test set: 56.12632541273035\n"
     ]
    }
   ],
   "source": [
    "## Run the test examples through the model.\n",
    "errors = outputs = 0\n",
    "for i in range(num_tests):\n",
    "    test = np_test[i, 2:6]\n",
    "    prediction = model_0.predict(np.array([test]))\n",
    "    out = np_test[i, 1]\n",
    "    \n",
    "    print(\"Prediction: {}, Expected: {}\".format(prediction[0][0], out))\n",
    "    errors += abs(prediction - out)\n",
    "    outputs += abs(out)\n",
    "    \n",
    "errors = errors[0][0]  ## Extract out the single real number.\n",
    "print('')\n",
    "print('Mean error on test set: {}'.format(errors / num_tests))\n",
    "print('Mean error % on test set: {}'.format(errors / outputs * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
